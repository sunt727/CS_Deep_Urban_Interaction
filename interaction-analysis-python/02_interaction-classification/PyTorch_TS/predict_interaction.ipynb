{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning with PyTorch\n",
    "We're going to train a neural network to classify dogs and cats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init, helpers, utils, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.models as models\n",
    "import os\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets.folder import ImageFolder, default_loader\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from torchvision import transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "IMG_SIZE = 224  #224  #defined by NN model input\n",
    "_mean = [0.485, 0.456, 0.406]\n",
    "_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "train_trans = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE,IMG_SIZE)),  #256  #(IMG_SIZE, IMG_SIZE)  # some images are pretty small\n",
    "    #transforms.RandomCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(.3, .3, .3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_mean, _std),\n",
    "])\n",
    "val_trans = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE,IMG_SIZE)),  #256  #(IMG_SIZE, IMG_SIZE)\n",
    "    #transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_mean, _std),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(test_ds) = 1421. \n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128  #2  #256  #512  #32  #220 for resnet152 on Dell Presison 5520 laptop, 400 for resnet18\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# use trained model to predict a pair of people in a new image\n",
    "\n",
    "# test data set\n",
    "test_ds = ImageFolder(\"data/raw/DUI/test\", transform=val_trans, loader=default_loader)\n",
    "print(f'len(test_ds) = {len(test_ds)}. ')\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict with Trained Model\n",
    "\n",
    "Pickle the trained model and predict image with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulding VGG19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuo/anaconda3/envs/torch36/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py:24: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    }
   ],
   "source": [
    "# from one origin image to one canvas and predicted people boundaries\n",
    "\n",
    "from predict_boxes import predict_boxes \n",
    "\n",
    "weight_name = 'network/weight/pose_model.pth'\n",
    "# test_image = 'readme/ski.jpg'\n",
    "\n",
    "# canvas, all_predicts = predict_boxes(test_image, weight_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "from network.ResNet_ronorigin import *\n",
    "model = resnet_18()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict, WIP\n",
    "\n",
    "# Eval\n",
    "model.eval()  # IMPORTANT\n",
    "\n",
    "with torch.no_grad():  # IMPORTANT\n",
    "    for image_batch in imagefolder:\n",
    "        \n",
    "        # image_batch to single image\n",
    "        canvas, all_predicts = predict_boxes(image_batch, weight_name)\n",
    "        \n",
    "        # canvas to crop\n",
    "        pred = model(canvas, crop)\n",
    "        \n",
    "        # link and visualize\n",
    "        \n",
    "        # cv2.rectangle\n",
    "        # cv2.curve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch36]",
   "language": "python",
   "name": "conda-env-torch36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
